{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os \n",
    "import sys\n",
    "import skimage.draw\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = \"/allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/data/datasciencebowl2018/stage1_train\"\n",
    "val_dataset   = \"/allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/data/datasciencebowl2018/stage1_val\"\n",
    "weights = \"/allen/programs/celltypes/workgroups/em-connectomics/gayathrim/gits/Mask_RCNN/mask_rcnn_coco.h5\"\n",
    "weights = \"/allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/vesicles_model_v1.h5\"\n",
    "logs = \"/allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/logs\"\n",
    "command = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"../../\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR) \n",
    "\n",
    "from mrcnn import model as modellib, utils, visualize\n",
    "from vesicles import VesicleDataset, VesicleConfig\n",
    "\n",
    "\n",
    "# Path to trained weights file\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "\n",
    "\n",
    "# Directory to save logs and model checkpoints, if not provided\n",
    "# through the command line argument --logs\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "\n",
    "\n",
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a \n",
    "    central point to control graph sizes.\n",
    "\n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    # Training dataset.\n",
    "    dataset_train = VesicleDataset()\n",
    "    dataset_train.load_vesicle(train_dataset)\n",
    "    dataset_train.prepare()\n",
    "\n",
    "    # Validation dataset\n",
    "    dataset_val = VesicleDataset()\n",
    "    dataset_val.load_vesicle(val_dataset)\n",
    "    dataset_val.prepare()\n",
    "\n",
    "    # *** This training schedule is an example. Update to your needs ***\n",
    "    # Since we're using a very small dataset, and starting from\n",
    "    # COCO trained weights, we don't need to train too long. Also,\n",
    "    # no need to train all layers, just the heads should do it.\n",
    "    print(\"Training network heads\")\n",
    "    #model.train(dataset_train, dataset_val,\n",
    "    #            learning_rate=config.LEARNING_RATE,\n",
    "    #            epochs=30,\n",
    "    #            layers='heads')\n",
    "\n",
    "    # Training - Stage 2\n",
    "    # Finetune layers from ResNet stage 4 and up\n",
    "    print(\"Fine tune Resnet stage 4 and up\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=40,\n",
    "                layers='4+')\n",
    "\n",
    "    # Training - Stage 3\n",
    "    # Fine tune all layers\n",
    "    print(\"Fine tune all layers\")\n",
    "    model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE / 10,\n",
    "                epochs=70,\n",
    "                layers='all')\n",
    "\n",
    "\n",
    "def test(model, image_path):\n",
    "    print(\"Running on {}\".format(image_path))\n",
    "    \n",
    "    # Read image\n",
    "    image = skimage.io.imread(image_path)\n",
    "\n",
    "    # detect objects\n",
    "    r = model.detect([image], verbose=1)[0]\n",
    "\n",
    "    # Display results\n",
    "    ax = get_ax(1)\n",
    "    visualize.display_instances(image, r['rois'], r['masks'], r['class_ids'],\n",
    "                                [\"Background\", \"IC\"], r['scores'], ax=ax,\n",
    "                                title=\"Predictions\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0327 18:24:40.540176 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0327 18:24:40.573536 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0327 18:24:40.607275 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0327 18:24:40.641825 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1919: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0327 18:24:40.646507 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     2\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 2\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'mrcnn_mask_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           vesicles\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                50\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0327 18:24:43.926426 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0327 18:24:44.706632 140287092823808 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/array_ops.py:1354: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0327 18:24:44.865433 140287092823808 deprecation_wrapper.py:119] From /allen/programs/celltypes/workgroups/em-connectomics/gayathrim/gits/Mask_RCNN/mrcnn/model.py:554: The name tf.random_shuffle is deprecated. Please use tf.random.shuffle instead.\n",
      "\n",
      "W0327 18:24:44.944606 140287092823808 deprecation_wrapper.py:119] From /allen/programs/celltypes/workgroups/em-connectomics/gayathrim/gits/Mask_RCNN/mrcnn/utils.py:200: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0327 18:24:44.973391 140287092823808 deprecation.py:506] From /allen/programs/celltypes/workgroups/em-connectomics/gayathrim/gits/Mask_RCNN/mrcnn/model.py:601: calling crop_and_resize_v1 (from tensorflow.python.ops.image_ops_impl) with box_ind is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "box_ind is deprecated, use box_indices instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/vesicles_model_v1.h5\n",
      "\n",
      "vesicle\n",
      "\n",
      "vesicle\n",
      "Training network heads\n",
      "Fine tune Resnet stage 4 and up\n",
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/logs/vesicles20200327T1824/mask_rcnn_vesicles_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0327 18:24:57.768494 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0327 18:25:17.105041 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0327 18:25:17.106225 140287092823808 deprecation_wrapper.py:119] From /usr/local/lib/python3.5/dist-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "50/50 [==============================] - 1500s 30s/step - loss: 1.1564 - rpn_class_loss: 0.0287 - rpn_bbox_loss: 0.1157 - mrcnn_class_loss: 0.3631 - mrcnn_bbox_loss: 0.2507 - mrcnn_mask_loss: 0.3982 - val_loss: 1.4359 - val_rpn_class_loss: 0.0694 - val_rpn_bbox_loss: 0.1998 - val_mrcnn_class_loss: 0.3736 - val_mrcnn_bbox_loss: 0.3245 - val_mrcnn_mask_loss: 0.4685\n",
      "Epoch 2/40\n",
      "50/50 [==============================] - 1306s 26s/step - loss: 0.6173 - rpn_class_loss: 0.0169 - rpn_bbox_loss: 0.0987 - mrcnn_class_loss: 0.2523 - mrcnn_bbox_loss: 0.0698 - mrcnn_mask_loss: 0.1795 - val_loss: 1.8506 - val_rpn_class_loss: 0.1980 - val_rpn_bbox_loss: 0.4166 - val_mrcnn_class_loss: 0.4787 - val_mrcnn_bbox_loss: 0.2864 - val_mrcnn_mask_loss: 0.4709\n",
      "Epoch 3/40\n",
      "50/50 [==============================] - 1314s 26s/step - loss: 0.9395 - rpn_class_loss: 0.0279 - rpn_bbox_loss: 0.2479 - mrcnn_class_loss: 0.2183 - mrcnn_bbox_loss: 0.1447 - mrcnn_mask_loss: 0.3008 - val_loss: 2.9127 - val_rpn_class_loss: 0.1358 - val_rpn_bbox_loss: 1.2795 - val_mrcnn_class_loss: 0.3195 - val_mrcnn_bbox_loss: 0.3860 - val_mrcnn_mask_loss: 0.7918\n",
      "Epoch 4/40\n",
      "50/50 [==============================] - 1314s 26s/step - loss: 0.5429 - rpn_class_loss: 0.0081 - rpn_bbox_loss: 0.0657 - mrcnn_class_loss: 0.1451 - mrcnn_bbox_loss: 0.0887 - mrcnn_mask_loss: 0.2353 - val_loss: 1.1403 - val_rpn_class_loss: 0.0111 - val_rpn_bbox_loss: 0.2108 - val_mrcnn_class_loss: 0.2961 - val_mrcnn_bbox_loss: 0.1598 - val_mrcnn_mask_loss: 0.4625\n",
      "Epoch 5/40\n",
      "50/50 [==============================] - 1303s 26s/step - loss: 0.6601 - rpn_class_loss: 0.0021 - rpn_bbox_loss: 0.0547 - mrcnn_class_loss: 0.3310 - mrcnn_bbox_loss: 0.0583 - mrcnn_mask_loss: 0.2139 - val_loss: 0.9455 - val_rpn_class_loss: 0.0207 - val_rpn_bbox_loss: 0.1528 - val_mrcnn_class_loss: 0.1472 - val_mrcnn_bbox_loss: 0.1300 - val_mrcnn_mask_loss: 0.4949\n",
      "Epoch 6/40\n",
      "50/50 [==============================] - 1318s 26s/step - loss: 0.4161 - rpn_class_loss: 0.0016 - rpn_bbox_loss: 0.0546 - mrcnn_class_loss: 0.1729 - mrcnn_bbox_loss: 0.0567 - mrcnn_mask_loss: 0.1303 - val_loss: 1.2547 - val_rpn_class_loss: 0.0412 - val_rpn_bbox_loss: 0.2223 - val_mrcnn_class_loss: 0.2553 - val_mrcnn_bbox_loss: 0.2086 - val_mrcnn_mask_loss: 0.5273\n",
      "Epoch 7/40\n",
      "50/50 [==============================] - 1299s 26s/step - loss: 0.4564 - rpn_class_loss: 0.0089 - rpn_bbox_loss: 0.0538 - mrcnn_class_loss: 0.1188 - mrcnn_bbox_loss: 0.0686 - mrcnn_mask_loss: 0.2062 - val_loss: 0.7715 - val_rpn_class_loss: 0.0366 - val_rpn_bbox_loss: 0.1417 - val_mrcnn_class_loss: 0.2260 - val_mrcnn_bbox_loss: 0.1170 - val_mrcnn_mask_loss: 0.2502\n",
      "Epoch 8/40\n",
      "50/50 [==============================] - 1313s 26s/step - loss: 0.4431 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0626 - mrcnn_class_loss: 0.1194 - mrcnn_bbox_loss: 0.0650 - mrcnn_mask_loss: 0.1938 - val_loss: 1.3383 - val_rpn_class_loss: 0.0636 - val_rpn_bbox_loss: 0.2122 - val_mrcnn_class_loss: 0.4617 - val_mrcnn_bbox_loss: 0.1948 - val_mrcnn_mask_loss: 0.4060\n",
      "Epoch 9/40\n",
      "50/50 [==============================] - 1305s 26s/step - loss: 0.3761 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0435 - mrcnn_class_loss: 0.0889 - mrcnn_bbox_loss: 0.0456 - mrcnn_mask_loss: 0.1966 - val_loss: 0.6486 - val_rpn_class_loss: 0.0015 - val_rpn_bbox_loss: 0.1049 - val_mrcnn_class_loss: 0.1282 - val_mrcnn_bbox_loss: 0.1382 - val_mrcnn_mask_loss: 0.2759\n",
      "Epoch 10/40\n",
      "50/50 [==============================] - 1309s 26s/step - loss: 0.5763 - rpn_class_loss: 0.0071 - rpn_bbox_loss: 0.0724 - mrcnn_class_loss: 0.1650 - mrcnn_bbox_loss: 0.0722 - mrcnn_mask_loss: 0.2596 - val_loss: 1.1451 - val_rpn_class_loss: 0.0107 - val_rpn_bbox_loss: 0.3772 - val_mrcnn_class_loss: 0.1136 - val_mrcnn_bbox_loss: 0.2690 - val_mrcnn_mask_loss: 0.3746\n",
      "Epoch 11/40\n",
      "50/50 [==============================] - 1288s 26s/step - loss: 0.3062 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0477 - mrcnn_class_loss: 0.0551 - mrcnn_bbox_loss: 0.0467 - mrcnn_mask_loss: 0.1542 - val_loss: 1.5627 - val_rpn_class_loss: 0.1852 - val_rpn_bbox_loss: 0.4314 - val_mrcnn_class_loss: 0.2185 - val_mrcnn_bbox_loss: 0.1786 - val_mrcnn_mask_loss: 0.5489\n",
      "Epoch 12/40\n",
      "50/50 [==============================] - 1357s 27s/step - loss: 0.4267 - rpn_class_loss: 0.0133 - rpn_bbox_loss: 0.0673 - mrcnn_class_loss: 0.1197 - mrcnn_bbox_loss: 0.0550 - mrcnn_mask_loss: 0.1714 - val_loss: 1.9332 - val_rpn_class_loss: 0.1615 - val_rpn_bbox_loss: 0.3503 - val_mrcnn_class_loss: 0.2510 - val_mrcnn_bbox_loss: 0.1909 - val_mrcnn_mask_loss: 0.9795\n",
      "Epoch 13/40\n",
      "50/50 [==============================] - 1359s 27s/step - loss: 0.5602 - rpn_class_loss: 0.0082 - rpn_bbox_loss: 0.0490 - mrcnn_class_loss: 0.2491 - mrcnn_bbox_loss: 0.0517 - mrcnn_mask_loss: 0.2022 - val_loss: 1.3392 - val_rpn_class_loss: 0.0223 - val_rpn_bbox_loss: 0.0673 - val_mrcnn_class_loss: 0.1967 - val_mrcnn_bbox_loss: 0.0715 - val_mrcnn_mask_loss: 0.9812\n",
      "Epoch 14/40\n",
      "50/50 [==============================] - 1323s 26s/step - loss: 0.7656 - rpn_class_loss: 0.0366 - rpn_bbox_loss: 0.1660 - mrcnn_class_loss: 0.2070 - mrcnn_bbox_loss: 0.1084 - mrcnn_mask_loss: 0.2476 - val_loss: 2.1117 - val_rpn_class_loss: 0.2507 - val_rpn_bbox_loss: 0.4235 - val_mrcnn_class_loss: 0.6144 - val_mrcnn_bbox_loss: 0.2132 - val_mrcnn_mask_loss: 0.6099\n",
      "Epoch 15/40\n",
      "50/50 [==============================] - 1332s 27s/step - loss: 0.5526 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.0653 - mrcnn_class_loss: 0.1687 - mrcnn_bbox_loss: 0.0832 - mrcnn_mask_loss: 0.2283 - val_loss: 2.8630 - val_rpn_class_loss: 0.3939 - val_rpn_bbox_loss: 0.5524 - val_mrcnn_class_loss: 0.7802 - val_mrcnn_bbox_loss: 0.2604 - val_mrcnn_mask_loss: 0.8760\n",
      "Epoch 16/40\n",
      "50/50 [==============================] - 1313s 26s/step - loss: 0.3436 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.0464 - mrcnn_class_loss: 0.1048 - mrcnn_bbox_loss: 0.0470 - mrcnn_mask_loss: 0.1412 - val_loss: 2.1389 - val_rpn_class_loss: 0.0663 - val_rpn_bbox_loss: 0.2293 - val_mrcnn_class_loss: 0.9092 - val_mrcnn_bbox_loss: 0.2106 - val_mrcnn_mask_loss: 0.7235\n",
      "Epoch 17/40\n",
      "50/50 [==============================] - 1321s 26s/step - loss: 0.5231 - rpn_class_loss: 0.0292 - rpn_bbox_loss: 0.0855 - mrcnn_class_loss: 0.1976 - mrcnn_bbox_loss: 0.0597 - mrcnn_mask_loss: 0.1510 - val_loss: 1.3576 - val_rpn_class_loss: 0.0536 - val_rpn_bbox_loss: 0.2134 - val_mrcnn_class_loss: 0.4983 - val_mrcnn_bbox_loss: 0.1810 - val_mrcnn_mask_loss: 0.4112\n",
      "Epoch 18/40\n",
      "50/50 [==============================] - 1311s 26s/step - loss: 0.7899 - rpn_class_loss: 0.0245 - rpn_bbox_loss: 0.1300 - mrcnn_class_loss: 0.2920 - mrcnn_bbox_loss: 0.0951 - mrcnn_mask_loss: 0.2484 - val_loss: 1.1953 - val_rpn_class_loss: 0.0566 - val_rpn_bbox_loss: 0.1950 - val_mrcnn_class_loss: 0.2852 - val_mrcnn_bbox_loss: 0.1698 - val_mrcnn_mask_loss: 0.4886\n",
      "Epoch 19/40\n",
      "50/50 [==============================] - 1314s 26s/step - loss: 0.5369 - rpn_class_loss: 0.0115 - rpn_bbox_loss: 0.0878 - mrcnn_class_loss: 0.1550 - mrcnn_bbox_loss: 0.0761 - mrcnn_mask_loss: 0.2065 - val_loss: 1.3986 - val_rpn_class_loss: 0.1345 - val_rpn_bbox_loss: 0.2085 - val_mrcnn_class_loss: 0.4027 - val_mrcnn_bbox_loss: 0.2155 - val_mrcnn_mask_loss: 0.4374\n",
      "Epoch 20/40\n",
      "50/50 [==============================] - 1319s 26s/step - loss: 0.2641 - rpn_class_loss: 0.0018 - rpn_bbox_loss: 0.0324 - mrcnn_class_loss: 0.0606 - mrcnn_bbox_loss: 0.0354 - mrcnn_mask_loss: 0.1338 - val_loss: 2.0798 - val_rpn_class_loss: 0.2185 - val_rpn_bbox_loss: 0.3021 - val_mrcnn_class_loss: 0.8442 - val_mrcnn_bbox_loss: 0.2344 - val_mrcnn_mask_loss: 0.4806\n",
      "Epoch 21/40\n",
      "50/50 [==============================] - 1314s 26s/step - loss: 0.3692 - rpn_class_loss: 0.0180 - rpn_bbox_loss: 0.0470 - mrcnn_class_loss: 0.1100 - mrcnn_bbox_loss: 0.0370 - mrcnn_mask_loss: 0.1572 - val_loss: 2.5938 - val_rpn_class_loss: 0.3862 - val_rpn_bbox_loss: 0.3406 - val_mrcnn_class_loss: 0.7633 - val_mrcnn_bbox_loss: 0.3476 - val_mrcnn_mask_loss: 0.7561\n",
      "Epoch 22/40\n",
      "50/50 [==============================] - 1310s 26s/step - loss: 0.4295 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.0606 - mrcnn_class_loss: 0.1431 - mrcnn_bbox_loss: 0.0573 - mrcnn_mask_loss: 0.1619 - val_loss: 1.6303 - val_rpn_class_loss: 0.1352 - val_rpn_bbox_loss: 0.2294 - val_mrcnn_class_loss: 0.3117 - val_mrcnn_bbox_loss: 0.2300 - val_mrcnn_mask_loss: 0.7240\n",
      "Epoch 23/40\n",
      "50/50 [==============================] - 1328s 27s/step - loss: 0.3787 - rpn_class_loss: 0.0023 - rpn_bbox_loss: 0.0352 - mrcnn_class_loss: 0.0985 - mrcnn_bbox_loss: 0.0395 - mrcnn_mask_loss: 0.2033 - val_loss: 1.4992 - val_rpn_class_loss: 0.0733 - val_rpn_bbox_loss: 0.2758 - val_mrcnn_class_loss: 0.4532 - val_mrcnn_bbox_loss: 0.2061 - val_mrcnn_mask_loss: 0.4907\n",
      "Epoch 24/40\n",
      "50/50 [==============================] - 1316s 26s/step - loss: 0.3221 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.0555 - mrcnn_class_loss: 0.1063 - mrcnn_bbox_loss: 0.0380 - mrcnn_mask_loss: 0.1162 - val_loss: 1.8774 - val_rpn_class_loss: 0.1281 - val_rpn_bbox_loss: 0.2857 - val_mrcnn_class_loss: 0.7376 - val_mrcnn_bbox_loss: 0.2280 - val_mrcnn_mask_loss: 0.4979\n",
      "Epoch 25/40\n",
      "50/50 [==============================] - 1309s 26s/step - loss: 0.4368 - rpn_class_loss: 0.0072 - rpn_bbox_loss: 0.0696 - mrcnn_class_loss: 0.1525 - mrcnn_bbox_loss: 0.0563 - mrcnn_mask_loss: 0.1512 - val_loss: 1.1918 - val_rpn_class_loss: 0.0442 - val_rpn_bbox_loss: 0.1298 - val_mrcnn_class_loss: 0.6104 - val_mrcnn_bbox_loss: 0.1086 - val_mrcnn_mask_loss: 0.2987\n",
      "Epoch 26/40\n",
      "50/50 [==============================] - 1328s 27s/step - loss: 0.4788 - rpn_class_loss: 0.0049 - rpn_bbox_loss: 0.0627 - mrcnn_class_loss: 0.1417 - mrcnn_bbox_loss: 0.0531 - mrcnn_mask_loss: 0.2163 - val_loss: 0.9631 - val_rpn_class_loss: 0.0174 - val_rpn_bbox_loss: 0.1015 - val_mrcnn_class_loss: 0.3676 - val_mrcnn_bbox_loss: 0.1154 - val_mrcnn_mask_loss: 0.3612\n",
      "Epoch 27/40\n",
      "50/50 [==============================] - 1332s 27s/step - loss: 0.3450 - rpn_class_loss: 0.0044 - rpn_bbox_loss: 0.0357 - mrcnn_class_loss: 0.0836 - mrcnn_bbox_loss: 0.0374 - mrcnn_mask_loss: 0.1839 - val_loss: 0.8782 - val_rpn_class_loss: 0.0333 - val_rpn_bbox_loss: 0.1140 - val_mrcnn_class_loss: 0.3402 - val_mrcnn_bbox_loss: 0.0905 - val_mrcnn_mask_loss: 0.3002\n",
      "Epoch 28/40\n",
      "50/50 [==============================] - 1323s 26s/step - loss: 0.4451 - rpn_class_loss: 0.0101 - rpn_bbox_loss: 0.0733 - mrcnn_class_loss: 0.1176 - mrcnn_bbox_loss: 0.0613 - mrcnn_mask_loss: 0.1827 - val_loss: 1.1177 - val_rpn_class_loss: 0.0723 - val_rpn_bbox_loss: 0.1958 - val_mrcnn_class_loss: 0.2884 - val_mrcnn_bbox_loss: 0.1304 - val_mrcnn_mask_loss: 0.4308\n",
      "Epoch 29/40\n",
      "50/50 [==============================] - 1296s 26s/step - loss: 0.4312 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.0888 - mrcnn_class_loss: 0.1019 - mrcnn_bbox_loss: 0.0577 - mrcnn_mask_loss: 0.1757 - val_loss: 1.1021 - val_rpn_class_loss: 0.0289 - val_rpn_bbox_loss: 0.1892 - val_mrcnn_class_loss: 0.3497 - val_mrcnn_bbox_loss: 0.1810 - val_mrcnn_mask_loss: 0.3533\n",
      "Epoch 30/40\n",
      "50/50 [==============================] - 1333s 27s/step - loss: 0.3880 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.0486 - mrcnn_class_loss: 0.0786 - mrcnn_bbox_loss: 0.0487 - mrcnn_mask_loss: 0.2051 - val_loss: 1.3110 - val_rpn_class_loss: 0.0348 - val_rpn_bbox_loss: 0.1992 - val_mrcnn_class_loss: 0.4464 - val_mrcnn_bbox_loss: 0.2003 - val_mrcnn_mask_loss: 0.4304\n",
      "Epoch 31/40\n",
      "50/50 [==============================] - 1302s 26s/step - loss: 0.4673 - rpn_class_loss: 0.0134 - rpn_bbox_loss: 0.1015 - mrcnn_class_loss: 0.1175 - mrcnn_bbox_loss: 0.0690 - mrcnn_mask_loss: 0.1660 - val_loss: 1.3529 - val_rpn_class_loss: 0.0828 - val_rpn_bbox_loss: 0.2472 - val_mrcnn_class_loss: 0.4120 - val_mrcnn_bbox_loss: 0.1933 - val_mrcnn_mask_loss: 0.4175\n",
      "Epoch 32/40\n",
      "50/50 [==============================] - 1307s 26s/step - loss: 0.4153 - rpn_class_loss: 0.0052 - rpn_bbox_loss: 0.0907 - mrcnn_class_loss: 0.0902 - mrcnn_bbox_loss: 0.0592 - mrcnn_mask_loss: 0.1700 - val_loss: 1.8025 - val_rpn_class_loss: 0.2266 - val_rpn_bbox_loss: 0.3617 - val_mrcnn_class_loss: 0.3917 - val_mrcnn_bbox_loss: 0.2024 - val_mrcnn_mask_loss: 0.6201\n",
      "Epoch 33/40\n",
      "50/50 [==============================] - 1301s 26s/step - loss: 0.3865 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.0533 - mrcnn_class_loss: 0.1714 - mrcnn_bbox_loss: 0.0304 - mrcnn_mask_loss: 0.1210 - val_loss: 1.8578 - val_rpn_class_loss: 0.1469 - val_rpn_bbox_loss: 0.4027 - val_mrcnn_class_loss: 0.4256 - val_mrcnn_bbox_loss: 0.2372 - val_mrcnn_mask_loss: 0.6453\n",
      "Epoch 34/40\n",
      "50/50 [==============================] - 1311s 26s/step - loss: 0.4625 - rpn_class_loss: 0.0080 - rpn_bbox_loss: 0.0576 - mrcnn_class_loss: 0.1887 - mrcnn_bbox_loss: 0.0517 - mrcnn_mask_loss: 0.1564 - val_loss: 1.2763 - val_rpn_class_loss: 0.0287 - val_rpn_bbox_loss: 0.2686 - val_mrcnn_class_loss: 0.2317 - val_mrcnn_bbox_loss: 0.1685 - val_mrcnn_mask_loss: 0.5787\n",
      "Epoch 35/40\n",
      "50/50 [==============================] - 1318s 26s/step - loss: 0.4891 - rpn_class_loss: 0.0086 - rpn_bbox_loss: 0.1449 - mrcnn_class_loss: 0.1306 - mrcnn_bbox_loss: 0.0596 - mrcnn_mask_loss: 0.1454 - val_loss: 1.2785 - val_rpn_class_loss: 0.0559 - val_rpn_bbox_loss: 0.1946 - val_mrcnn_class_loss: 0.2895 - val_mrcnn_bbox_loss: 0.1519 - val_mrcnn_mask_loss: 0.5866\n",
      "Epoch 36/40\n",
      "50/50 [==============================] - 1329s 27s/step - loss: 0.5462 - rpn_class_loss: 0.0058 - rpn_bbox_loss: 0.1050 - mrcnn_class_loss: 0.2081 - mrcnn_bbox_loss: 0.0541 - mrcnn_mask_loss: 0.1733 - val_loss: 0.9593 - val_rpn_class_loss: 0.0472 - val_rpn_bbox_loss: 0.2065 - val_mrcnn_class_loss: 0.2849 - val_mrcnn_bbox_loss: 0.1297 - val_mrcnn_mask_loss: 0.2910\n",
      "Epoch 37/40\n",
      "50/50 [==============================] - 1318s 26s/step - loss: 0.2070 - rpn_class_loss: 0.0017 - rpn_bbox_loss: 0.0199 - mrcnn_class_loss: 0.0395 - mrcnn_bbox_loss: 0.0191 - mrcnn_mask_loss: 0.1268 - val_loss: 1.2283 - val_rpn_class_loss: 0.0448 - val_rpn_bbox_loss: 0.2285 - val_mrcnn_class_loss: 0.4962 - val_mrcnn_bbox_loss: 0.0956 - val_mrcnn_mask_loss: 0.3632\n",
      "Epoch 38/40\n",
      "50/50 [==============================] - 1311s 26s/step - loss: 0.4980 - rpn_class_loss: 0.0060 - rpn_bbox_loss: 0.0597 - mrcnn_class_loss: 0.1366 - mrcnn_bbox_loss: 0.0640 - mrcnn_mask_loss: 0.2318 - val_loss: 1.7681 - val_rpn_class_loss: 0.0682 - val_rpn_bbox_loss: 0.2557 - val_mrcnn_class_loss: 0.7906 - val_mrcnn_bbox_loss: 0.1415 - val_mrcnn_mask_loss: 0.5122\n",
      "Epoch 39/40\n",
      "50/50 [==============================] - 1319s 26s/step - loss: 0.5181 - rpn_class_loss: 0.0087 - rpn_bbox_loss: 0.0795 - mrcnn_class_loss: 0.1440 - mrcnn_bbox_loss: 0.0752 - mrcnn_mask_loss: 0.2107 - val_loss: 1.2196 - val_rpn_class_loss: 0.0282 - val_rpn_bbox_loss: 0.1918 - val_mrcnn_class_loss: 0.3871 - val_mrcnn_bbox_loss: 0.1436 - val_mrcnn_mask_loss: 0.4688\n",
      "Epoch 40/40\n",
      "50/50 [==============================] - 1317s 26s/step - loss: 0.5138 - rpn_class_loss: 0.0088 - rpn_bbox_loss: 0.0804 - mrcnn_class_loss: 0.1360 - mrcnn_bbox_loss: 0.0693 - mrcnn_mask_loss: 0.2192 - val_loss: 1.4094 - val_rpn_class_loss: 0.0331 - val_rpn_bbox_loss: 0.1631 - val_mrcnn_class_loss: 0.8166 - val_mrcnn_bbox_loss: 0.1327 - val_mrcnn_mask_loss: 0.2640\n",
      "Fine tune all layers\n",
      "\n",
      "Starting at epoch 40. LR=0.0001\n",
      "\n",
      "Checkpoint Path: /allen/programs/celltypes/workgroups/em-connectomics/gayathrim/vesicle_detection/logs/vesicles20200327T1824/mask_rcnn_vesicles_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "conv1                  (Conv2D)\n",
      "bn_conv1               (BatchNorm)\n",
      "res2a_branch2a         (Conv2D)\n",
      "bn2a_branch2a          (BatchNorm)\n",
      "res2a_branch2b         (Conv2D)\n",
      "bn2a_branch2b          (BatchNorm)\n",
      "res2a_branch2c         (Conv2D)\n",
      "res2a_branch1          (Conv2D)\n",
      "bn2a_branch2c          (BatchNorm)\n",
      "bn2a_branch1           (BatchNorm)\n",
      "res2b_branch2a         (Conv2D)\n",
      "bn2b_branch2a          (BatchNorm)\n",
      "res2b_branch2b         (Conv2D)\n",
      "bn2b_branch2b          (BatchNorm)\n",
      "res2b_branch2c         (Conv2D)\n",
      "bn2b_branch2c          (BatchNorm)\n",
      "res2c_branch2a         (Conv2D)\n",
      "bn2c_branch2a          (BatchNorm)\n",
      "res2c_branch2b         (Conv2D)\n",
      "bn2c_branch2b          (BatchNorm)\n",
      "res2c_branch2c         (Conv2D)\n",
      "bn2c_branch2c          (BatchNorm)\n",
      "res3a_branch2a         (Conv2D)\n",
      "bn3a_branch2a          (BatchNorm)\n",
      "res3a_branch2b         (Conv2D)\n",
      "bn3a_branch2b          (BatchNorm)\n",
      "res3a_branch2c         (Conv2D)\n",
      "res3a_branch1          (Conv2D)\n",
      "bn3a_branch2c          (BatchNorm)\n",
      "bn3a_branch1           (BatchNorm)\n",
      "res3b_branch2a         (Conv2D)\n",
      "bn3b_branch2a          (BatchNorm)\n",
      "res3b_branch2b         (Conv2D)\n",
      "bn3b_branch2b          (BatchNorm)\n",
      "res3b_branch2c         (Conv2D)\n",
      "bn3b_branch2c          (BatchNorm)\n",
      "res3c_branch2a         (Conv2D)\n",
      "bn3c_branch2a          (BatchNorm)\n",
      "res3c_branch2b         (Conv2D)\n",
      "bn3c_branch2b          (BatchNorm)\n",
      "res3c_branch2c         (Conv2D)\n",
      "bn3c_branch2c          (BatchNorm)\n",
      "res3d_branch2a         (Conv2D)\n",
      "bn3d_branch2a          (BatchNorm)\n",
      "res3d_branch2b         (Conv2D)\n",
      "bn3d_branch2b          (BatchNorm)\n",
      "res3d_branch2c         (Conv2D)\n",
      "bn3d_branch2c          (BatchNorm)\n",
      "res4a_branch2a         (Conv2D)\n",
      "bn4a_branch2a          (BatchNorm)\n",
      "res4a_branch2b         (Conv2D)\n",
      "bn4a_branch2b          (BatchNorm)\n",
      "res4a_branch2c         (Conv2D)\n",
      "res4a_branch1          (Conv2D)\n",
      "bn4a_branch2c          (BatchNorm)\n",
      "bn4a_branch1           (BatchNorm)\n",
      "res4b_branch2a         (Conv2D)\n",
      "bn4b_branch2a          (BatchNorm)\n",
      "res4b_branch2b         (Conv2D)\n",
      "bn4b_branch2b          (BatchNorm)\n",
      "res4b_branch2c         (Conv2D)\n",
      "bn4b_branch2c          (BatchNorm)\n",
      "res4c_branch2a         (Conv2D)\n",
      "bn4c_branch2a          (BatchNorm)\n",
      "res4c_branch2b         (Conv2D)\n",
      "bn4c_branch2b          (BatchNorm)\n",
      "res4c_branch2c         (Conv2D)\n",
      "bn4c_branch2c          (BatchNorm)\n",
      "res4d_branch2a         (Conv2D)\n",
      "bn4d_branch2a          (BatchNorm)\n",
      "res4d_branch2b         (Conv2D)\n",
      "bn4d_branch2b          (BatchNorm)\n",
      "res4d_branch2c         (Conv2D)\n",
      "bn4d_branch2c          (BatchNorm)\n",
      "res4e_branch2a         (Conv2D)\n",
      "bn4e_branch2a          (BatchNorm)\n",
      "res4e_branch2b         (Conv2D)\n",
      "bn4e_branch2b          (BatchNorm)\n",
      "res4e_branch2c         (Conv2D)\n",
      "bn4e_branch2c          (BatchNorm)\n",
      "res4f_branch2a         (Conv2D)\n",
      "bn4f_branch2a          (BatchNorm)\n",
      "res4f_branch2b         (Conv2D)\n",
      "bn4f_branch2b          (BatchNorm)\n",
      "res4f_branch2c         (Conv2D)\n",
      "bn4f_branch2c          (BatchNorm)\n",
      "res4g_branch2a         (Conv2D)\n",
      "bn4g_branch2a          (BatchNorm)\n",
      "res4g_branch2b         (Conv2D)\n",
      "bn4g_branch2b          (BatchNorm)\n",
      "res4g_branch2c         (Conv2D)\n",
      "bn4g_branch2c          (BatchNorm)\n",
      "res4h_branch2a         (Conv2D)\n",
      "bn4h_branch2a          (BatchNorm)\n",
      "res4h_branch2b         (Conv2D)\n",
      "bn4h_branch2b          (BatchNorm)\n",
      "res4h_branch2c         (Conv2D)\n",
      "bn4h_branch2c          (BatchNorm)\n",
      "res4i_branch2a         (Conv2D)\n",
      "bn4i_branch2a          (BatchNorm)\n",
      "res4i_branch2b         (Conv2D)\n",
      "bn4i_branch2b          (BatchNorm)\n",
      "res4i_branch2c         (Conv2D)\n",
      "bn4i_branch2c          (BatchNorm)\n",
      "res4j_branch2a         (Conv2D)\n",
      "bn4j_branch2a          (BatchNorm)\n",
      "res4j_branch2b         (Conv2D)\n",
      "bn4j_branch2b          (BatchNorm)\n",
      "res4j_branch2c         (Conv2D)\n",
      "bn4j_branch2c          (BatchNorm)\n",
      "res4k_branch2a         (Conv2D)\n",
      "bn4k_branch2a          (BatchNorm)\n",
      "res4k_branch2b         (Conv2D)\n",
      "bn4k_branch2b          (BatchNorm)\n",
      "res4k_branch2c         (Conv2D)\n",
      "bn4k_branch2c          (BatchNorm)\n",
      "res4l_branch2a         (Conv2D)\n",
      "bn4l_branch2a          (BatchNorm)\n",
      "res4l_branch2b         (Conv2D)\n",
      "bn4l_branch2b          (BatchNorm)\n",
      "res4l_branch2c         (Conv2D)\n",
      "bn4l_branch2c          (BatchNorm)\n",
      "res4m_branch2a         (Conv2D)\n",
      "bn4m_branch2a          (BatchNorm)\n",
      "res4m_branch2b         (Conv2D)\n",
      "bn4m_branch2b          (BatchNorm)\n",
      "res4m_branch2c         (Conv2D)\n",
      "bn4m_branch2c          (BatchNorm)\n",
      "res4n_branch2a         (Conv2D)\n",
      "bn4n_branch2a          (BatchNorm)\n",
      "res4n_branch2b         (Conv2D)\n",
      "bn4n_branch2b          (BatchNorm)\n",
      "res4n_branch2c         (Conv2D)\n",
      "bn4n_branch2c          (BatchNorm)\n",
      "res4o_branch2a         (Conv2D)\n",
      "bn4o_branch2a          (BatchNorm)\n",
      "res4o_branch2b         (Conv2D)\n",
      "bn4o_branch2b          (BatchNorm)\n",
      "res4o_branch2c         (Conv2D)\n",
      "bn4o_branch2c          (BatchNorm)\n",
      "res4p_branch2a         (Conv2D)\n",
      "bn4p_branch2a          (BatchNorm)\n",
      "res4p_branch2b         (Conv2D)\n",
      "bn4p_branch2b          (BatchNorm)\n",
      "res4p_branch2c         (Conv2D)\n",
      "bn4p_branch2c          (BatchNorm)\n",
      "res4q_branch2a         (Conv2D)\n",
      "bn4q_branch2a          (BatchNorm)\n",
      "res4q_branch2b         (Conv2D)\n",
      "bn4q_branch2b          (BatchNorm)\n",
      "res4q_branch2c         (Conv2D)\n",
      "bn4q_branch2c          (BatchNorm)\n",
      "res4r_branch2a         (Conv2D)\n",
      "bn4r_branch2a          (BatchNorm)\n",
      "res4r_branch2b         (Conv2D)\n",
      "bn4r_branch2b          (BatchNorm)\n",
      "res4r_branch2c         (Conv2D)\n",
      "bn4r_branch2c          (BatchNorm)\n",
      "res4s_branch2a         (Conv2D)\n",
      "bn4s_branch2a          (BatchNorm)\n",
      "res4s_branch2b         (Conv2D)\n",
      "bn4s_branch2b          (BatchNorm)\n",
      "res4s_branch2c         (Conv2D)\n",
      "bn4s_branch2c          (BatchNorm)\n",
      "res4t_branch2a         (Conv2D)\n",
      "bn4t_branch2a          (BatchNorm)\n",
      "res4t_branch2b         (Conv2D)\n",
      "bn4t_branch2b          (BatchNorm)\n",
      "res4t_branch2c         (Conv2D)\n",
      "bn4t_branch2c          (BatchNorm)\n",
      "res4u_branch2a         (Conv2D)\n",
      "bn4u_branch2a          (BatchNorm)\n",
      "res4u_branch2b         (Conv2D)\n",
      "bn4u_branch2b          (BatchNorm)\n",
      "res4u_branch2c         (Conv2D)\n",
      "bn4u_branch2c          (BatchNorm)\n",
      "res4v_branch2a         (Conv2D)\n",
      "bn4v_branch2a          (BatchNorm)\n",
      "res4v_branch2b         (Conv2D)\n",
      "bn4v_branch2b          (BatchNorm)\n",
      "res4v_branch2c         (Conv2D)\n",
      "bn4v_branch2c          (BatchNorm)\n",
      "res4w_branch2a         (Conv2D)\n",
      "bn4w_branch2a          (BatchNorm)\n",
      "res4w_branch2b         (Conv2D)\n",
      "bn4w_branch2b          (BatchNorm)\n",
      "res4w_branch2c         (Conv2D)\n",
      "bn4w_branch2c          (BatchNorm)\n",
      "res5a_branch2a         (Conv2D)\n",
      "bn5a_branch2a          (BatchNorm)\n",
      "res5a_branch2b         (Conv2D)\n",
      "bn5a_branch2b          (BatchNorm)\n",
      "res5a_branch2c         (Conv2D)\n",
      "res5a_branch1          (Conv2D)\n",
      "bn5a_branch2c          (BatchNorm)\n",
      "bn5a_branch1           (BatchNorm)\n",
      "res5b_branch2a         (Conv2D)\n",
      "bn5b_branch2a          (BatchNorm)\n",
      "res5b_branch2b         (Conv2D)\n",
      "bn5b_branch2b          (BatchNorm)\n",
      "res5b_branch2c         (Conv2D)\n",
      "bn5b_branch2c          (BatchNorm)\n",
      "res5c_branch2a         (Conv2D)\n",
      "bn5c_branch2a          (BatchNorm)\n",
      "res5c_branch2b         (Conv2D)\n",
      "bn5c_branch2b          (BatchNorm)\n",
      "res5c_branch2c         (Conv2D)\n",
      "bn5c_branch2c          (BatchNorm)\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n",
      "Epoch 41/70\n",
      "50/50 [==============================] - 1665s 33s/step - loss: 1.1779 - rpn_class_loss: 0.0564 - rpn_bbox_loss: 0.2318 - mrcnn_class_loss: 0.3902 - mrcnn_bbox_loss: 0.1648 - mrcnn_mask_loss: 0.3347 - val_loss: 1.4602 - val_rpn_class_loss: 0.0550 - val_rpn_bbox_loss: 0.1418 - val_mrcnn_class_loss: 0.4586 - val_mrcnn_bbox_loss: 0.2395 - val_mrcnn_mask_loss: 0.5652\n",
      "Epoch 42/70\n",
      "50/50 [==============================] - 1444s 29s/step - loss: 0.7739 - rpn_class_loss: 0.0229 - rpn_bbox_loss: 0.1087 - mrcnn_class_loss: 0.3835 - mrcnn_bbox_loss: 0.0777 - mrcnn_mask_loss: 0.1812 - val_loss: 1.2755 - val_rpn_class_loss: 0.1277 - val_rpn_bbox_loss: 0.2781 - val_mrcnn_class_loss: 0.3139 - val_mrcnn_bbox_loss: 0.2116 - val_mrcnn_mask_loss: 0.3441\n",
      "Epoch 43/70\n",
      "50/50 [==============================] - 1434s 29s/step - loss: 0.9605 - rpn_class_loss: 0.0282 - rpn_bbox_loss: 0.2767 - mrcnn_class_loss: 0.2246 - mrcnn_bbox_loss: 0.1468 - mrcnn_mask_loss: 0.2842 - val_loss: 2.1299 - val_rpn_class_loss: 0.1210 - val_rpn_bbox_loss: 0.9947 - val_mrcnn_class_loss: 0.2983 - val_mrcnn_bbox_loss: 0.2591 - val_mrcnn_mask_loss: 0.4568\n",
      "Epoch 44/70\n",
      "50/50 [==============================] - 1434s 29s/step - loss: 0.7062 - rpn_class_loss: 0.0061 - rpn_bbox_loss: 0.0855 - mrcnn_class_loss: 0.2321 - mrcnn_bbox_loss: 0.1205 - mrcnn_mask_loss: 0.2620 - val_loss: 1.1508 - val_rpn_class_loss: 0.0059 - val_rpn_bbox_loss: 0.2294 - val_mrcnn_class_loss: 0.3202 - val_mrcnn_bbox_loss: 0.1386 - val_mrcnn_mask_loss: 0.4567\n",
      "Epoch 45/70\n",
      "50/50 [==============================] - 1446s 29s/step - loss: 0.5561 - rpn_class_loss: 0.0025 - rpn_bbox_loss: 0.0554 - mrcnn_class_loss: 0.2343 - mrcnn_bbox_loss: 0.0535 - mrcnn_mask_loss: 0.2104 - val_loss: 0.7307 - val_rpn_class_loss: 0.0160 - val_rpn_bbox_loss: 0.1178 - val_mrcnn_class_loss: 0.1265 - val_mrcnn_bbox_loss: 0.0621 - val_mrcnn_mask_loss: 0.4082\n",
      "Epoch 46/70\n",
      "50/50 [==============================] - 1446s 29s/step - loss: 0.5897 - rpn_class_loss: 0.0076 - rpn_bbox_loss: 0.0688 - mrcnn_class_loss: 0.2721 - mrcnn_bbox_loss: 0.0660 - mrcnn_mask_loss: 0.1752 - val_loss: 1.1344 - val_rpn_class_loss: 0.0560 - val_rpn_bbox_loss: 0.2626 - val_mrcnn_class_loss: 0.2749 - val_mrcnn_bbox_loss: 0.1334 - val_mrcnn_mask_loss: 0.4075\n",
      "Epoch 47/70\n",
      "50/50 [==============================] - 1440s 29s/step - loss: 0.4374 - rpn_class_loss: 0.0104 - rpn_bbox_loss: 0.0594 - mrcnn_class_loss: 0.1238 - mrcnn_bbox_loss: 0.0558 - mrcnn_mask_loss: 0.1880 - val_loss: 0.6562 - val_rpn_class_loss: 0.0331 - val_rpn_bbox_loss: 0.1171 - val_mrcnn_class_loss: 0.1963 - val_mrcnn_bbox_loss: 0.0812 - val_mrcnn_mask_loss: 0.2286\n",
      "Epoch 48/70\n",
      "50/50 [==============================] - 1429s 29s/step - loss: 0.6652 - rpn_class_loss: 0.0159 - rpn_bbox_loss: 0.0909 - mrcnn_class_loss: 0.1905 - mrcnn_bbox_loss: 0.0991 - mrcnn_mask_loss: 0.2688 - val_loss: 1.2487 - val_rpn_class_loss: 0.0446 - val_rpn_bbox_loss: 0.1961 - val_mrcnn_class_loss: 0.4423 - val_mrcnn_bbox_loss: 0.1834 - val_mrcnn_mask_loss: 0.3824\n",
      "Epoch 49/70\n",
      "50/50 [==============================] - 1441s 29s/step - loss: 0.5031 - rpn_class_loss: 0.0047 - rpn_bbox_loss: 0.0681 - mrcnn_class_loss: 0.1411 - mrcnn_bbox_loss: 0.0624 - mrcnn_mask_loss: 0.2268 - val_loss: 0.5941 - val_rpn_class_loss: 0.0032 - val_rpn_bbox_loss: 0.1148 - val_mrcnn_class_loss: 0.1110 - val_mrcnn_bbox_loss: 0.1216 - val_mrcnn_mask_loss: 0.2436\n",
      "Epoch 50/70\n",
      "50/50 [==============================] - 1448s 29s/step - loss: 0.5084 - rpn_class_loss: 0.0066 - rpn_bbox_loss: 0.0636 - mrcnn_class_loss: 0.1411 - mrcnn_bbox_loss: 0.0619 - mrcnn_mask_loss: 0.2352 - val_loss: 0.9216 - val_rpn_class_loss: 0.0375 - val_rpn_bbox_loss: 0.1597 - val_mrcnn_class_loss: 0.1680 - val_mrcnn_bbox_loss: 0.1900 - val_mrcnn_mask_loss: 0.3664\n",
      "Epoch 51/70\n",
      "50/50 [==============================] - 1446s 29s/step - loss: 0.5715 - rpn_class_loss: 0.0216 - rpn_bbox_loss: 0.0956 - mrcnn_class_loss: 0.1572 - mrcnn_bbox_loss: 0.0831 - mrcnn_mask_loss: 0.2140 - val_loss: 1.0289 - val_rpn_class_loss: 0.0856 - val_rpn_bbox_loss: 0.1622 - val_mrcnn_class_loss: 0.1997 - val_mrcnn_bbox_loss: 0.0978 - val_mrcnn_mask_loss: 0.4835\n",
      "Epoch 52/70\n",
      "50/50 [==============================] - 1452s 29s/step - loss: 0.5317 - rpn_class_loss: 0.0084 - rpn_bbox_loss: 0.0600 - mrcnn_class_loss: 0.2125 - mrcnn_bbox_loss: 0.0608 - mrcnn_mask_loss: 0.1900 - val_loss: 1.7605 - val_rpn_class_loss: 0.2051 - val_rpn_bbox_loss: 0.3085 - val_mrcnn_class_loss: 0.3154 - val_mrcnn_bbox_loss: 0.1888 - val_mrcnn_mask_loss: 0.7427\n",
      "Epoch 53/70\n",
      "50/50 [==============================] - 1477s 30s/step - loss: 0.6725 - rpn_class_loss: 0.0194 - rpn_bbox_loss: 0.1140 - mrcnn_class_loss: 0.2300 - mrcnn_bbox_loss: 0.0864 - mrcnn_mask_loss: 0.2228 - val_loss: 1.4191 - val_rpn_class_loss: 0.0793 - val_rpn_bbox_loss: 0.1126 - val_mrcnn_class_loss: 0.2680 - val_mrcnn_bbox_loss: 0.1056 - val_mrcnn_mask_loss: 0.8536\n",
      "Epoch 54/70\n",
      "50/50 [==============================] - 1455s 29s/step - loss: 0.6168 - rpn_class_loss: 0.0170 - rpn_bbox_loss: 0.1154 - mrcnn_class_loss: 0.1992 - mrcnn_bbox_loss: 0.0891 - mrcnn_mask_loss: 0.1960 - val_loss: 1.6401 - val_rpn_class_loss: 0.1754 - val_rpn_bbox_loss: 0.2825 - val_mrcnn_class_loss: 0.3959 - val_mrcnn_bbox_loss: 0.1661 - val_mrcnn_mask_loss: 0.6202\n",
      "Epoch 55/70\n",
      "50/50 [==============================] - 1455s 29s/step - loss: 0.6699 - rpn_class_loss: 0.0097 - rpn_bbox_loss: 0.1115 - mrcnn_class_loss: 0.2034 - mrcnn_bbox_loss: 0.1110 - mrcnn_mask_loss: 0.2343 - val_loss: 2.2386 - val_rpn_class_loss: 0.2879 - val_rpn_bbox_loss: 0.4609 - val_mrcnn_class_loss: 0.6463 - val_mrcnn_bbox_loss: 0.2514 - val_mrcnn_mask_loss: 0.5921\n",
      "Epoch 56/70\n",
      "50/50 [==============================] - 1431s 29s/step - loss: 0.3807 - rpn_class_loss: 0.0035 - rpn_bbox_loss: 0.0458 - mrcnn_class_loss: 0.1160 - mrcnn_bbox_loss: 0.0558 - mrcnn_mask_loss: 0.1596 - val_loss: 1.3348 - val_rpn_class_loss: 0.0407 - val_rpn_bbox_loss: 0.2054 - val_mrcnn_class_loss: 0.5305 - val_mrcnn_bbox_loss: 0.1276 - val_mrcnn_mask_loss: 0.4307\n",
      "Epoch 57/70\n",
      "50/50 [==============================] - 1447s 29s/step - loss: 0.4358 - rpn_class_loss: 0.0070 - rpn_bbox_loss: 0.0602 - mrcnn_class_loss: 0.1577 - mrcnn_bbox_loss: 0.0527 - mrcnn_mask_loss: 0.1582 - val_loss: 1.2727 - val_rpn_class_loss: 0.0496 - val_rpn_bbox_loss: 0.2092 - val_mrcnn_class_loss: 0.4701 - val_mrcnn_bbox_loss: 0.1558 - val_mrcnn_mask_loss: 0.3880\n",
      "Epoch 58/70\n",
      "50/50 [==============================] - 1448s 29s/step - loss: 0.6871 - rpn_class_loss: 0.0120 - rpn_bbox_loss: 0.1068 - mrcnn_class_loss: 0.2461 - mrcnn_bbox_loss: 0.0942 - mrcnn_mask_loss: 0.2280 - val_loss: 1.2101 - val_rpn_class_loss: 0.0595 - val_rpn_bbox_loss: 0.1774 - val_mrcnn_class_loss: 0.2929 - val_mrcnn_bbox_loss: 0.1709 - val_mrcnn_mask_loss: 0.5094\n",
      "Epoch 59/70\n",
      "50/50 [==============================] - 1438s 29s/step - loss: 0.5491 - rpn_class_loss: 0.0086 - rpn_bbox_loss: 0.0923 - mrcnn_class_loss: 0.1536 - mrcnn_bbox_loss: 0.0831 - mrcnn_mask_loss: 0.2115 - val_loss: 1.2747 - val_rpn_class_loss: 0.1449 - val_rpn_bbox_loss: 0.1898 - val_mrcnn_class_loss: 0.3458 - val_mrcnn_bbox_loss: 0.1772 - val_mrcnn_mask_loss: 0.4171\n",
      "Epoch 60/70\n",
      "50/50 [==============================] - 1432s 29s/step - loss: 0.2888 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0358 - mrcnn_class_loss: 0.0743 - mrcnn_bbox_loss: 0.0363 - mrcnn_mask_loss: 0.1397 - val_loss: 1.5981 - val_rpn_class_loss: 0.1481 - val_rpn_bbox_loss: 0.2499 - val_mrcnn_class_loss: 0.5446 - val_mrcnn_bbox_loss: 0.2423 - val_mrcnn_mask_loss: 0.4132\n",
      "Epoch 61/70\n",
      "50/50 [==============================] - 1430s 29s/step - loss: 0.2804 - rpn_class_loss: 0.0026 - rpn_bbox_loss: 0.0344 - mrcnn_class_loss: 0.0676 - mrcnn_bbox_loss: 0.0276 - mrcnn_mask_loss: 0.1483 - val_loss: 2.3071 - val_rpn_class_loss: 0.3304 - val_rpn_bbox_loss: 0.3050 - val_mrcnn_class_loss: 0.6393 - val_mrcnn_bbox_loss: 0.2906 - val_mrcnn_mask_loss: 0.7419\n",
      "Epoch 62/70\n",
      "50/50 [==============================] - 1433s 29s/step - loss: 0.3767 - rpn_class_loss: 0.0046 - rpn_bbox_loss: 0.0591 - mrcnn_class_loss: 0.1043 - mrcnn_bbox_loss: 0.0486 - mrcnn_mask_loss: 0.1600 - val_loss: 1.7209 - val_rpn_class_loss: 0.1639 - val_rpn_bbox_loss: 0.1936 - val_mrcnn_class_loss: 0.3934 - val_mrcnn_bbox_loss: 0.1736 - val_mrcnn_mask_loss: 0.7965\n",
      "Epoch 63/70\n",
      "50/50 [==============================] - 1449s 29s/step - loss: 0.3768 - rpn_class_loss: 0.0024 - rpn_bbox_loss: 0.0461 - mrcnn_class_loss: 0.1040 - mrcnn_bbox_loss: 0.0458 - mrcnn_mask_loss: 0.1786 - val_loss: 1.3658 - val_rpn_class_loss: 0.0756 - val_rpn_bbox_loss: 0.2563 - val_mrcnn_class_loss: 0.3640 - val_mrcnn_bbox_loss: 0.1916 - val_mrcnn_mask_loss: 0.4783\n",
      "Epoch 64/70\n",
      "50/50 [==============================] - 1440s 29s/step - loss: 0.2501 - rpn_class_loss: 0.0011 - rpn_bbox_loss: 0.0337 - mrcnn_class_loss: 0.0851 - mrcnn_bbox_loss: 0.0274 - mrcnn_mask_loss: 0.1028 - val_loss: 1.6091 - val_rpn_class_loss: 0.0970 - val_rpn_bbox_loss: 0.2564 - val_mrcnn_class_loss: 0.5945 - val_mrcnn_bbox_loss: 0.2127 - val_mrcnn_mask_loss: 0.4485\n",
      "Epoch 65/70\n",
      "50/50 [==============================] - 1438s 29s/step - loss: 0.3870 - rpn_class_loss: 0.0020 - rpn_bbox_loss: 0.0521 - mrcnn_class_loss: 0.1226 - mrcnn_bbox_loss: 0.0513 - mrcnn_mask_loss: 0.1590 - val_loss: 1.1540 - val_rpn_class_loss: 0.0413 - val_rpn_bbox_loss: 0.1310 - val_mrcnn_class_loss: 0.5641 - val_mrcnn_bbox_loss: 0.1194 - val_mrcnn_mask_loss: 0.2981\n",
      "Epoch 66/70\n",
      "50/50 [==============================] - 1433s 29s/step - loss: 0.4336 - rpn_class_loss: 0.0043 - rpn_bbox_loss: 0.0664 - mrcnn_class_loss: 0.1192 - mrcnn_bbox_loss: 0.0527 - mrcnn_mask_loss: 0.1910 - val_loss: 1.2222 - val_rpn_class_loss: 0.0214 - val_rpn_bbox_loss: 0.0741 - val_mrcnn_class_loss: 0.4588 - val_mrcnn_bbox_loss: 0.1347 - val_mrcnn_mask_loss: 0.5332\n",
      "Epoch 67/70\n",
      "50/50 [==============================] - 1429s 29s/step - loss: 0.2077 - rpn_class_loss: 0.0015 - rpn_bbox_loss: 0.0225 - mrcnn_class_loss: 0.0621 - mrcnn_bbox_loss: 0.0293 - mrcnn_mask_loss: 0.0924 - val_loss: 0.8092 - val_rpn_class_loss: 0.0187 - val_rpn_bbox_loss: 0.0877 - val_mrcnn_class_loss: 0.2830 - val_mrcnn_bbox_loss: 0.0996 - val_mrcnn_mask_loss: 0.3201\n",
      "Epoch 68/70\n",
      "50/50 [==============================] - 1446s 29s/step - loss: 0.2528 - rpn_class_loss: 0.0014 - rpn_bbox_loss: 0.0311 - mrcnn_class_loss: 0.0790 - mrcnn_bbox_loss: 0.0350 - mrcnn_mask_loss: 0.1063 - val_loss: 1.0072 - val_rpn_class_loss: 0.0534 - val_rpn_bbox_loss: 0.1626 - val_mrcnn_class_loss: 0.2531 - val_mrcnn_bbox_loss: 0.1108 - val_mrcnn_mask_loss: 0.4273\n",
      "Epoch 69/70\n",
      "50/50 [==============================] - 1439s 29s/step - loss: 0.3474 - rpn_class_loss: 9.2339e-04 - rpn_bbox_loss: 0.0462 - mrcnn_class_loss: 0.0859 - mrcnn_bbox_loss: 0.0502 - mrcnn_mask_loss: 0.1642 - val_loss: 0.9661 - val_rpn_class_loss: 0.0270 - val_rpn_bbox_loss: 0.1833 - val_mrcnn_class_loss: 0.3062 - val_mrcnn_bbox_loss: 0.1384 - val_mrcnn_mask_loss: 0.3113\n",
      "Epoch 70/70\n",
      "50/50 [==============================] - 1431s 29s/step - loss: 0.3934 - rpn_class_loss: 0.0034 - rpn_bbox_loss: 0.0430 - mrcnn_class_loss: 0.0810 - mrcnn_bbox_loss: 0.0497 - mrcnn_mask_loss: 0.2163 - val_loss: 1.3369 - val_rpn_class_loss: 0.0528 - val_rpn_bbox_loss: 0.1915 - val_mrcnn_class_loss: 0.4383 - val_mrcnn_bbox_loss: 0.1791 - val_mrcnn_mask_loss: 0.4751\n"
     ]
    }
   ],
   "source": [
    "# Configurations\n",
    "if command == \"train\":\n",
    "    config = VesicleConfig()\n",
    "else:\n",
    "    class InferenceConfig(VesicleInferenceConfig):\n",
    "        # Set batch size to 1 since we'll be running inference on\n",
    "        # one image at a time. Batch size = GPU_COUNT * IMAGES_PER_GPU\n",
    "        GPU_COUNT = 1\n",
    "        IMAGES_PER_GPU = 1\n",
    "    config = InferenceConfig()\n",
    "config.display()\n",
    "\n",
    "# Create model\n",
    "if command == \"train\":\n",
    "    model = modellib.MaskRCNN(mode=\"training\", config=config,\n",
    "                              model_dir=logs)\n",
    "else:\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", config=config,\n",
    "                              model_dir=logs)\n",
    "\n",
    "weights_path = weights\n",
    "\n",
    "# Load weights\n",
    "print(\"Loading weights \", weights_path)\n",
    "# Exclude the last layers because they require a matching\n",
    "# number of classes\n",
    "model.load_weights(weights_path, by_name=True, exclude=[\n",
    "    \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "    \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "\n",
    "# Train or evaluate\n",
    "if command == \"train\":\n",
    "    train(model, train_dataset)\n",
    "elif command == \"test\":\n",
    "    test(model, image_path=image)\n",
    "else:\n",
    "    print(\"'{}' is not recognized. \"\n",
    "          \"Use 'train' or 'test'\".format(command))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
